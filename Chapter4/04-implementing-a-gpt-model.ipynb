{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Architecture\n",
    "\n",
    "GPT stands for generative pre-trained transformer and are large deep networks trained to predict the next word in a sequence. Their architecture consists of a stacked number of transformer blocks which we will implement here.\n",
    "\n",
    "In order to load the weights of GPT-2 later on, we will use the parameters used for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,     # trained on ~50k tokens using BPE tokenizer\n",
    "    \"context_length\": 1024,  # the max number of input tokens the model can handle\n",
    "    \"emb_dim\": 768,          # the dimension of the embeddings\n",
    "    \"n_heads\": 12,           # the number of attention heads\n",
    "    \"n_layers\": 12,          # the number of transformer blocks\n",
    "    \"drop_rate\": 0.1,        # the dropout rate to prevent overfitting\n",
    "    \"qkv_bias\": False        # whether to use bias in the QKV linear layer\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by implementing a DummyGPTModel class to make it easier to see what else needs implementing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(config[\"vocab_size\"], config[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(config[\"context_length\"], config[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(config[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(config)\n",
    "            for _ in range(config[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = DummyLayerNorm(config[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(config[\"emb_dim\"], config[\"vocab_size\"], bias=False)\n",
    "        \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dummy implementation consists of\n",
    "\n",
    "- token embeddings\n",
    "- positional embeddings\n",
    "- dropout\n",
    "- transformer blocks\n",
    "- final layer norm\n",
    "- linear output head\n",
    "\n",
    "In the forward method we can see how the input data flows through the various components.\n",
    "\n",
    "We now start by preparing our input data and initializing a new 124-million parameter Dummy GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "text1 = \"Every effort moves you\"\n",
    "text2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(text1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(text2)))\n",
    "batch = torch.stack(batch)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output logits shape: torch.Size([2, 4, 50257])\n",
      "Logits:\n",
      " tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output logits shape:\", logits.shape)\n",
    "print(\"Logits:\\n\", logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Normalization\n",
    "\n",
    "Training such deep neural networks can cause vanishing or exploding gradients which makes it difficult to find a set of parameters which minimizes the loss function.\n",
    "\n",
    "In order to improve the stability, we add `LayerNormalization` to the network. This normalization will make sure that the activations of a layer have a mean of 0 and a variance of 1 and will speed up convergence of the training process.\n",
    "\n",
    "To illustrate how this works, we go through a toy example of 2 inputs with 5 dimensions and look at the mean and variance before we apply layer normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 6])\n",
      "Output:\n",
      " tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Mean: tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance: tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5)\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(\"Output shape:\", out.shape)\n",
    "print(\"Output:\\n\", out)\n",
    "\n",
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Variance:\", var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply layer normalization before checking mean and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized output:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)  # Improve readability\n",
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized output:\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to implement a class `LayerNorm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        # unbiased=False means we divide by N instead of N-1\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        out = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return out * self.scale + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying it to our test input we find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer_norm = LayerNorm(emb_dim=5)\n",
    "out_norm = layer_norm(batch_example)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True, unbiased=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-forward network with GELU activation\n",
    "\n",
    "We need to implement a small feed-forward network as part of the transformer block. Here, we will start by implementing the GELU activation which is a smooth variant of the ReLU activation.\n",
    "\n",
    "$$GELU(x) \\approx 0.5 \\cdot x \\cdot \\big( 1 + tanh \\big[ \\sqrt{ \\frac{2}{\\pi} } \\cdot \\big( x + 0.044715 \\cdot x^3 \\big) \\big] \\big)$$\n",
    "\n",
    "We implement class `GELU` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (\n",
    "            1 + torch.tanh(\n",
    "                torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "                (x + 0.044715 * torch.pow(x, 3))\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot it to get a better idea of its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-5, 5, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smoothness of the GELU function compared to teh ReLU leads to better optimization properties during training which allows for smoother adjustment of the model parameters.\n",
    "\n",
    "Now we use the GELU function to implement our feed-forward network class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(config[\"emb_dim\"], 4 * config[\"emb_dim\"]),  # Increase the hidden dimension\n",
    "            GELU(),\n",
    "            nn.Linear(4 * config[\"emb_dim\"], config[\"emb_dim\"]),  # Decrease the output dimension\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.randn(2, 3, GPT_CONFIG_124M[\"emb_dim\"])\n",
    "out = ffn(x)\n",
    "print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding shortcut connections\n",
    "\n",
    "Shortcut connection are also called skip or residual connections and allow the input activation and the gradient during back-propagation to pass by a layer. Those connections have been introduced to mitigate the vanishing gradient problem and play a crucial part to maintain the gradient during backpropagation.\n",
    "\n",
    "As an example we implement a example deep network below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Linear(layer_sizes[i], layer_sizes[i+1]),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x_out = layer(x)\n",
    "            if self.use_shortcut and x.shape == x_out.shape:\n",
    "                x = x + x_out\n",
    "            else:\n",
    "                x = x_out\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the example network with and without shortcut connections and look at their gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without shortcut connections:\n",
      "layers.0.0.weight has gradient mean of 0.0006875665276311338\n",
      "layers.1.0.weight has gradient mean of 0.0019083978841081262\n",
      "layers.2.0.weight has gradient mean of 0.0038205476012080908\n",
      "layers.3.0.weight has gradient mean of 0.0038610314950346947\n",
      "layers.4.0.weight has gradient mean of 0.02481495402753353\n",
      "\n",
      "With shortcut connections:\n",
      "layers.0.0.weight has gradient mean of 0.5557742714881897\n",
      "layers.1.0.weight has gradient mean of 0.09135337918996811\n",
      "layers.2.0.weight has gradient mean of 0.7913904190063477\n",
      "layers.3.0.weight has gradient mean of 0.21711303293704987\n",
      "layers.4.0.weight has gradient mean of 3.140749216079712\n"
     ]
    }
   ],
   "source": [
    "def print_gradient(model, x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "\n",
    "\n",
    "# Initialize the network without shortcut connections\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "use_shortcut = False\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)\n",
    "model_wo_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut)\n",
    "print(\"Without shortcut connections:\")\n",
    "print_gradient(model_wo_shortcut, sample_input)\n",
    "print()\n",
    "# Initialize the network with shortcut connections\n",
    "torch.manual_seed(123)\n",
    "use_shortcut = True\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut)\n",
    "print(\"With shortcut connections:\")\n",
    "print_gradient(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it together in a transformer block\n",
    "\n",
    "Now that we have implemented the various parts required to create a transformer block, we can create class `TransformerBlock`, using the `MultiHeadAttention` we implemented in Chapter 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "\n",
    "from Chapter3.multihead_attention import MultiHeadAttention\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(\n",
    "            d_in=config[\"emb_dim\"],\n",
    "            d_out=config[\"emb_dim\"],\n",
    "            context_length=config[\"context_length\"],\n",
    "            dropout=config[\"drop_rate\"],\n",
    "            num_heads=config[\"n_heads\"],\n",
    "            qkv_bias=config[\"qkv_bias\"]\n",
    "        )\n",
    "        self.feed_forward = FeedForward(config)\n",
    "        self.ln1 = LayerNorm(config[\"emb_dim\"])\n",
    "        self.ln2 = LayerNorm(config[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(config[\"drop_rate\"])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply the attention block with shortcut connection\n",
    "        shortcut = x\n",
    "        x = self.ln1(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        # Apply the feed-forward network with shortcut connection\n",
    "        shortcut = x\n",
    "        x = self.ln2(x)\n",
    "        x = self.feed_forward(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we apply layer normalization *before* the two components of the transformer block and dropout after each component (PreLayerNorm). The original implementation of the transformer applied layer normalization *after* self-attention and feed-forward network which often lead to worse training dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the transformer block on our sample input. Comparing input and output shape we see that each transformer block does not alter the dimension of the input. This is crucial feature of the architecture which allows its application to many sequence-to-sequence tasks. While the dimension doesn't change, the encoded information in the output context vector does encapsulate the full input sequence. So the output vector is updated with the new contextual information from the entire input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.randn(2, 4, GPT_CONFIG_124M[\"emb_dim\"])\n",
    "transformer_block = TransformerBlock(GPT_CONFIG_124M)\n",
    "out = transformer_block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The GPT model\n",
    "\n",
    "We are now ready to put the full GPT model architecture together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(config[\"vocab_size\"], config[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(config[\"context_length\"], config[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(config[\"drop_rate\"])\n",
    "        \n",
    "        self.transformer_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(config) for _ in range(config[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(config[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(config[\"emb_dim\"], config[\"vocab_size\"], bias=False)\n",
    "        \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "Output logits shape: torch.Size([2, 4, 50257])\n",
      "Output logits:\n",
      " tensor([[[ 0.3613,  0.4223, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "gpt_model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = gpt_model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"Output logits shape:\", out.shape)\n",
    "print(\"Output logits:\\n\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shape is `[2, 4, 50257]` as we have 2 input samples with 4 dimensions each. The last dimension corresponds to the vocabulary size of the tokenizer which is `50257`.\n",
    "\n",
    "We can find the total number of parameters of the model using the `numel()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in gpt_model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason the number of parameters is not the expected 124 million of GPT-2 is due to the concept of *weight tying* used in the original GPT-2 implementation. It re-uses the token embedding layer in it's output layer.\n",
    "\n",
    "If we print the shape of the token embedding layer and remove the parameters of the output layer from the overall parameter count we end up at the expected 124 million of the original GPT-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n",
      "Total number of parameters (GPT-2): 124,412,160\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token embedding layer shape: {gpt_model.tok_emb.weight.shape}\")\n",
    "print(f\"Output layer shape: {gpt_model.out_head.weight.shape}\")\n",
    "\n",
    "total_params_gpt2 = (\n",
    "    total_params - sum(p.numel() for p in gpt_model.out_head.parameters())\n",
    ")\n",
    "print(f\"Total number of parameters (GPT-2): {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While weight tying reduces the overall number of parameters and thus the memory footprint of the model, it can also lead to worse training results. For this reason modern LLMs do usually not use weight tying.\n",
    "\n",
    "Another interesting measure to compute is the memory requirement of the model. We will do this for the version without weight tying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory requirement: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4  # Assuming float32 precision\n",
    "total_size_mb = total_size_bytes / (1024 ** 2)\n",
    "print(f\"Total memory requirement: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are initializing the smallest GPT-2 version here with 163 million parameters with\n",
    "\n",
    "- a context length of 1024\n",
    "- an embedding dimension of 768\n",
    "- 12 attention heads\n",
    "- 12 transformer blocks\n",
    "\n",
    "GPT-2 large in comparison consists of\n",
    "\n",
    "- a context length of 1024\n",
    "- an embedding dimension of 1280\n",
    "- 20 attention heads\n",
    "- 36 transformer blocks\n",
    "\n",
    "which computes to ~770 million parameters and a memory footprint of ~3GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters (GPT-2 large): 773,891,840\n",
      "Total memory requirement: 2952.16 MB\n"
     ]
    }
   ],
   "source": [
    "GPT_LARGE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # trained on ~50k tokens using BPE tokenizer\n",
    "    \"context_length\": 1024,  # the max number of input tokens the model can handle\n",
    "    \"emb_dim\": 1280,         # the dimension of the embeddings\n",
    "    \"n_heads\": 20,           # the number of attention heads\n",
    "    \"n_layers\": 36,          # the number of transformer blocks\n",
    "    \"drop_rate\": 0.1,        # the dropout rate to prevent overfitting\n",
    "    \"qkv_bias\": False        # whether to use bias in the QKV linear layer\n",
    "}\n",
    "\n",
    "gpt_model_large = GPTModel(GPT_LARGE_CONFIG)\n",
    "total_params_large = sum(p.numel() for p in gpt_model_large.parameters())\n",
    "total_params_gpt2_large = (\n",
    "    total_params_large - sum(p.numel() for p in gpt_model_large.out_head.parameters())\n",
    ")\n",
    "print(f\"Total number of parameters (GPT-2 large): {total_params_gpt2_large:,}\")\n",
    "\n",
    "total_size_bytes = total_params_gpt2_large * 4  # Assuming float32 precision\n",
    "total_size_mb = total_size_bytes / (1024 ** 2)\n",
    "print(f\"Total memory requirement: {total_size_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Text\n",
    "\n",
    "As a final step we will implement the code required to convert the predicted output tokens to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # Subset on the last time step which has the logits of the next predicted token\n",
    "        logits = logits[:, -1, :]  # [batch_size, vocab_size]\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probs, dim=-1, keepdim=True)  # Picks the most likely token\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # And appends it to the running sequence\n",
    "        \n",
    "    return idx       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given we always pick the most likely next token, this is also called *greedy decoding*. We will implement further sampling techniques to obtain a more variable output in the next chapter.\n",
    "\n",
    "For the moment, we apply our text generation function to a test context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n",
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n",
      "Decoded text: Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
    "\n",
    "# Before we generate text, we set the mnodel into evaluation mode\n",
    "gpt_model.eval()\n",
    "out = generate_text_simple(\n",
    "    gpt_model,\n",
    "    encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))\n",
    "\n",
    "decoded_text = tokenizer.decode(out[0].squeeze().tolist())\n",
    "print(\"Decoded text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given we haven't trained the model, the output is a incoherent sequence of tokens. This will improve once we train our model in the next Chapter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
